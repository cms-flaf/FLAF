{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FLAF","text":"<p>FLAF - Flexible LAW-based Analysis Framework. Task workflow managed is done via LAW (Luigi Analysis Framework).</p>"},{"location":"#how-to-install","title":"How to install","text":"<ol> <li> <p>Setup ssh keys:</p> <ul> <li>On GitHub settings/keys</li> <li>On CERN GitLab profile/keys</li> </ul> </li> <li> <p>Clone the repository:   <pre><code>git clone --recursive git@github.com:cms-flaf/Framework.git FLAF\n</code></pre></p> </li> </ol>"},{"location":"#how-to-load-environment","title":"How to load environment","text":"<p>Following command activates the framework environment: <pre><code>source env.sh\n</code></pre></p>"},{"location":"#how-to-run-limits","title":"How to run limits","text":"<ol> <li> <p>As a temporary workaround, if you want to run multiplie commands, to avoid delays to load environment each time run:   <pre><code>cmbEnv /bin/zsh # or /bin/bash\n</code></pre>   Alternatively add <code>cmbEnv</code> in front of each command. E.g.   <pre><code>cmbEnv python3 -c 'print(\"hello\")'\n</code></pre></p> </li> <li> <p>Create datacards.   <pre><code>python3 StatInference/dc_make/create_datacards.py --input PATH_TO_SHAPES  --output PATH_TO_CARDS --config PATH_TO_CONFIG\n</code></pre>   Available configurations:</p> <ul> <li>For X-&gt;HH&gt;bbtautau Run 2: StatInference/config/x_hh_bbtautau_run2.yaml</li> <li>For X-&gt;HH-&gt;bbWW Run 3: StatInference/config/x_hh_bbww_run3.yaml</li> </ul> </li> <li> <p>Run limits.   <pre><code>law run PlotResonantLimits --version dev --datacards 'PATH_TO_CARDS/*.txt' --xsec fb --y-log\n</code></pre>   Hints:</p> <ul> <li>use <code>--workflow htcondor</code> to submit on HTCondor (by default it runs locally)</li> <li>add <code>--remove-output 4,a,y</code> to remove previous output files</li> <li>add <code>--print-status 0</code> to get status of the workflow (where <code>0</code> is a depth). Useful to get the output file name.</li> <li>for more details see cms-hh inference documentation</li> </ul> </li> </ol>"},{"location":"#how-to-run-nanoaod-nanoaod-skims-production","title":"How to run nanoAOD-&gt;nanoAOD skims production","text":"<pre><code>law run CreateNanoSkims --version prod_v1 --periods 2016,2016APV,2017,2018 --ignore-missing-samples True\n</code></pre>"},{"location":"#how-to-run-hhbtag-training-skim-ntuple-production","title":"How to run HHbtag training skim ntuple production","text":"<pre><code>python Studies/HHBTag/CreateTrainingSkim.py --inFile $CENTRAL_STORAGE/prod_v1/nanoAOD/2018/GluGluToBulkGravitonToHHTo2B2Tau_M-350.root --outFile output/skim.root --mass 350 --sample GluGluToBulkGraviton --year 2018 &gt;&amp; EventInfo.txt\npython Common/SaveHisto.txt --inFile $CENTRAL_STORAGE/prod_v1/nanoAOD/2018/GluGluToBulkGravitonToHHTo2B2Tau_M-350.root --outFile output/skim.root\n</code></pre>"},{"location":"#how-to-run-histogram-production","title":"How to run Histogram production","text":"<p>Please, see the file all_commands.txt (to be updated)</p>"},{"location":"hh_bbtautau/","title":"Simple commands","text":""},{"location":"hh_bbtautau/#deeptau-2p1","title":"DeepTau 2p1","text":""},{"location":"hh_bbtautau/#anacache-production","title":"AnaCache Production","text":"<pre><code>year=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run InputFileTask  --period Run2_${year} --version ${dir}\nyear=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run AnaCacheTask  --period Run2_${year} --workflow htcondor --version ${dir} --transfer-logs\n</code></pre>"},{"location":"hh_bbtautau/#anatuple-production-after-anacachetask","title":"AnaTuple Production (AFTER AnaCacheTask)","text":"<pre><code>year=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run InputFileTask  --period Run2_${year} --version ${dir}\nyear=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run AnaTupleTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs\nyear=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; mkdir /eos/user/v/vdamante/HH_bbtautau_resonant_Run2/${dir}/Run2_${year}/data\nyear=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run DataMergeTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs\n</code></pre>"},{"location":"hh_bbtautau/#anacachetuple-production-after-anatupletask","title":"AnaCacheTuple Production (AFTER AnaTupleTask)","text":"<pre><code>year=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run AnaCacheTupleTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs\n</code></pre>"},{"location":"hh_bbtautau/#histograms-production-after-anatupletask-but-not-necessairly-anacachetupletask","title":"Histograms Production (AFTER AnaTupleTask but NOT NECESSAIRLY AnaCacheTupleTask)","text":"<pre><code>year=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run HistProducerFileTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs\nyear=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run HistProducerSampleTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs\nyear=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run  MergeTask --period Run2_${year}  --version ${dir}  --workflow htcondor --transfer-logs\n</code></pre> <p>Work in progress <pre><code>year=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run  HistRebinnerTask --period Run2_${year}  --version ${dir}  --workflow htcondor --transfer-logs #This does something only for KinFit_m, currently\nyear=2016; dir=v8_deepTau2p1_onlyTauTau_HTT; law run  HaddMergedTask --period Run2_${year}  --version ${dir}  --workflow htcondor --transfer-logs\n</code></pre></p>"},{"location":"hh_bbtautau/#deeptau-2p5","title":"DeepTau 2p5","text":""},{"location":"hh_bbtautau/#anacache-production_1","title":"AnaCache Production","text":"<pre><code>year=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run InputFileTask  --period Run2_${year} --version ${dir}\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run AnaCacheTask  --period Run2_${year} --workflow htcondor --version ${dir} --transfer-logs --customisations deepTauVersion=2p5\n</code></pre>"},{"location":"hh_bbtautau/#anatuple-production-after-anacachetask_1","title":"AnaTuple Production (AFTER AnaCacheTask)","text":"<pre><code>year=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run InputFileTask  --period Run2_${year} --version ${dir}\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run AnaTupleTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs --customisations deepTauVersion=2p5\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; mkdir /eos/user/v/vdamante/HH_bbtautau_resonant_Run2/${dir}/Run2_${year}/data\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run DataMergeTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs --customisations deepTauVersion=2p5 # not sure it's needed in this step but I add it usually\n</code></pre>"},{"location":"hh_bbtautau/#anacachetuple-production-after-anatupletask_1","title":"AnaCacheTuple Production (AFTER AnaTupleTask)","text":"<pre><code>year=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run AnaCacheTupleTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs --customisations deepTauVersion=2p5\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; mkdir -p /eos/home-k/kandroso/cms-hh-bbtautau/anaCache/Run2_${year}/data/${dir}\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run DataCacheMergeTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs --customisations deepTauVersion=2p5\n</code></pre>"},{"location":"hh_bbtautau/#histograms-production-after-anatupletask-but-not-necessairly-anacachetupletask_1","title":"Histograms Production (AFTER AnaTupleTask but NOT NECESSAIRLY AnaCacheTupleTask)","text":"<pre><code>year=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run HistProducerFileTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run HistProducerSampleTask --period Run2_${year} --version ${dir} --workflow htcondor --transfer-logs\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run  MergeTask --period Run2_${year}  --version ${dir}  --workflow htcondor --transfer-logs\n</code></pre> <p>Work in progress <pre><code>year=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run  HistRebinnerTask --period Run2_${year}  --version ${dir}  --workflow htcondor --transfer-logs #This does something only for KinFit_m, currently\nyear=2016; dir=v8_deepTau2p5_onlyTauTau_HTT; law run  HaddMergedTask --period Run2_${year}  --version ${dir}  --workflow htcondor --transfer-logs\n</code></pre></p>"},{"location":"hh_bbtautau/#tips","title":"Tips","text":"<ol> <li>For local production switch from <code>--workflow htcondor</code> to <code>--workflow local</code></li> <li>To produce specific branches add <code>--branches X1,X2,...</code>, where <code>Xi</code> are the branch numbers</li> </ol>"}]}